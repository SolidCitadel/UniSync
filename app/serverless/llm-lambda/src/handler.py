"""
LLM Lambda Handler
ê³¼ì œ ë¶„ì„ ë° ì œì¶œë¬¼ ê²€ì¦ì„ ìœ„í•œ LLM í˜¸ì¶œ
"""

import json
import os
import boto3
import requests
from typing import Dict, List, Any

# í™˜ê²½ ë³€ìˆ˜
LLM_API_URL = os.environ.get('LLM_API_URL', 'https://api.openai.com/v1/chat/completions')
LLM_API_KEY = os.environ.get('LLM_API_KEY', '')
AWS_REGION = os.environ.get('AWS_REGION', 'ap-northeast-2')
SQS_ENDPOINT = os.environ.get('SQS_ENDPOINT', None)

# SQS í´ë¼ì´ì–¸íŠ¸
sqs = boto3.client('sqs', region_name=AWS_REGION, endpoint_url=SQS_ENDPOINT)


def lambda_handler(event, context):
    """
    SQS ì´ë²¤íŠ¸ë¡œ íŠ¸ë¦¬ê±°ë˜ëŠ” ë©”ì¸ í•¸ë“¤ëŸ¬

    Input (assignment-events-queue):
        {
            "eventType": "ASSIGNMENT_CREATED",
            "courseId": 123,
            "canvasAssignmentId": "canvas_456",
            "title": "ê³¼ì œ 1",
            "description": "...",
            "dueAt": "2025-11-30T23:59:00Z"
        }

    Input (submission-events-queue):
        {
            "eventType": "SUBMISSION_DETECTED",
            "userId": 5,
            "courseId": 123,
            "assignmentId": 10,
            "submissionMetadata": {...}
        }
    """
    try:
        # SQS ì´ë²¤íŠ¸ íŒŒì‹± (ë°°ì¹˜ ì²˜ë¦¬ ê°€ëŠ¥)
        for record in event['Records']:
            message_body = json.loads(record['body'])
            event_type = message_body.get('eventType')

            if event_type == 'ASSIGNMENT_CREATED':
                handle_assignment_analysis(message_body)
            elif event_type == 'SUBMISSION_DETECTED':
                handle_submission_validation(message_body)
            else:
                print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì´ë²¤íŠ¸ íƒ€ì…: {event_type}")

        return {'statusCode': 200, 'body': 'LLM ì²˜ë¦¬ ì™„ë£Œ'}

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        raise


def handle_assignment_analysis(message: Dict[str, Any]):
    """ê³¼ì œ ì„¤ëª…ì„ ë¶„ì„í•˜ì—¬ Task/Subtask ìƒì„±"""
    print(f"ğŸ¤– ê³¼ì œ ë¶„ì„ ì‹œì‘: {message['title']}")

    # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
ë‹¤ìŒ ê³¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ taskì™€ subtaskë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

ê³¼ì œ ì œëª©: {message['title']}
ê³¼ì œ ì„¤ëª…: {message['description']}
ë§ˆê°ì¼: {message['dueAt']}

JSON í˜•ì‹:
{{
  "tasks": [
    {{
      "title": "ë©”ì¸ task ì œëª©",
      "description": "ìƒì„¸ ì„¤ëª…",
      "priority": "HIGH",
      "subtasks": [
        {{
          "title": "subtask 1",
          "description": "...",
          "priority": "MEDIUM"
        }}
      ]
    }}
  ]
}}

ê·œì¹™:
- ê³¼ì œ íŠ¹ì„±ì— ë§ê²Œ 2-5ê°œì˜ subtaskë¡œ ë¶„í•´
- ìš°ì„ ìˆœìœ„: HIGH, MEDIUM, LOW
- ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì‘ì—…ìœ¼ë¡œ ë¶„í•´
"""

    # LLM API í˜¸ì¶œ
    llm_response = call_llm(prompt)

    # ì‘ë‹µ íŒŒì‹±
    tasks_data = json.loads(llm_response)

    # SQSë¡œ task-creation-queueì— ì „ì†¡
    send_to_sqs('task-creation-queue', {
        'eventType': 'TASKS_GENERATED',
        'courseId': message['courseId'],
        'canvasAssignmentId': message['canvasAssignmentId'],
        'tasks': tasks_data['tasks']
    })

    print(f"âœ… ê³¼ì œ ë¶„ì„ ì™„ë£Œ: {len(tasks_data['tasks'])}ê°œ task ìƒì„±")


def handle_submission_validation(message: Dict[str, Any]):
    """ì œì¶œë¬¼ ìœ íš¨ì„± ê²€ì¦"""
    print(f"ğŸ” ì œì¶œë¬¼ ê²€ì¦ ì‹œì‘: userId={message['userId']}")

    submission_meta = message['submissionMetadata']

    # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
ë‹¤ìŒ ì œì¶œë¬¼ì´ ê³¼ì œ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ëŠ”ì§€ ê²€ì¦í•´ì£¼ì„¸ìš”.

ì œì¶œ ì‹œê°: {submission_meta.get('submittedAt')}
ì œì¶œ ìœ í˜•: {submission_meta.get('submissionType')}
ì²¨ë¶€ íŒŒì¼: {len(submission_meta.get('attachments', []))}ê°œ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "isValid": true/false,
  "reason": "ê²€ì¦ ê²°ê³¼ ì„¤ëª…",
  "recommendation": "ì¶”ê°€ ì¡°ì¹˜ ì‚¬í•­"
}}
"""

    llm_response = call_llm(prompt)
    validation_result = json.loads(llm_response)

    # ìœ íš¨í•˜ë©´ Sync-Serviceë¡œ task ìƒíƒœ ì—…ë°ì´íŠ¸ ìš”ì²­
    if validation_result['isValid']:
        # TODO: Sync-Service API í˜¸ì¶œí•˜ì—¬ task ìƒíƒœë¥¼ DONEìœ¼ë¡œ ë³€ê²½
        print(f"âœ… ì œì¶œë¬¼ ìœ íš¨: task ìƒíƒœ ì—…ë°ì´íŠ¸ í•„ìš”")
    else:
        print(f"âš ï¸ ì œì¶œë¬¼ ë¶€ì í•©: {validation_result['reason']}")


def call_llm(prompt: str) -> str:
    """LLM API í˜¸ì¶œ (OpenAI/Claude ë“±)"""
    headers = {
        'Authorization': f'Bearer {LLM_API_KEY}',
        'Content-Type': 'application/json'
    }

    payload = {
        'model': 'gpt-4',
        'messages': [
            {'role': 'system', 'content': 'You are an AI assistant that helps students manage their assignments.'},
            {'role': 'user', 'content': prompt}
        ],
        'temperature': 0.7
    }

    response = requests.post(LLM_API_URL, headers=headers, json=payload, timeout=30)
    response.raise_for_status()

    data = response.json()
    return data['choices'][0]['message']['content']


def send_to_sqs(queue_name: str, message: Dict[str, Any]):
    """SQS íë¡œ ë©”ì‹œì§€ ì „ì†¡"""
    response = sqs.get_queue_url(QueueName=queue_name)
    queue_url = response['QueueUrl']

    sqs.send_message(
        QueueUrl=queue_url,
        MessageBody=json.dumps(message)
    )

    print(f"  â†’ SQS ì „ì†¡: {queue_name}")